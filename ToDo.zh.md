# 待办列表：CMG-TWIST 行走集成项目

本文档概述了将条件动作生成器（CMG）与 TWIST 集成以实现人形机器人基于速度命令行走的所需任务。

---

## 项目概览

**目标**：通过使用 CMG 生成参考动作和 TWIST 跟踪动作，使人形机器人能够根据速度命令行走。

**当前状态**：
- ✅ CMG 可从速度命令生成动作
- ✅ TWIST 可在物理机器人上跟踪参考动作
- ✅ DOF对齐完成（TWIST已更新为29 DOF配置）
- ❌ 集成管道尚未建立
- ❌ 端到端测试未执行

---

## 第 1 阶段：数据格式与关节映射

### 1.1 数据格式与关节映射
**优先级**：HIGH  
**工作量**：High

#### 1.1.1 29 DOF 配置对齐 ✅ **已完成**
**当前状态**：✅ TWIST已更新为29 DOF配置

- [x] **已完成：TWIST配置更新为29 DOF**
  - **解决方案**：将TWIST从23 DOF更新为29 DOF以对齐CMG和实机
  - **实施日期**：2026年1月30日
  - **详细信息**：
    - CMG输出：29 DOF（已训练完成）
    - TWIST配置：从23 DOF更新为29 DOF
    - 实机配置：29 DOF
    - URDF文件：使用官方 `g1_29dof.urdf`（来自unitree_mujoco）
  - **关节结构**（29 DOF）：
    - 左腿：6 DOF（hip_pitch/roll/yaw, knee, ankle_pitch/roll）
    - 右腿：6 DOF
    - 腰部：3 DOF（waist_yaw/roll/pitch）
    - 左臂：4 DOF（shoulder_pitch/roll/yaw, elbow）
    - 左手腕：3 DOF（wrist_roll/pitch/yaw）✨ **新增**
    - 右臂：4 DOF
    - 右手腕：3 DOF ✨ **新增**
  - **配置文件**：`legged_gym/legged_gym/envs/g1/g1_mimic_distill_config.py`
  - **无需映射**：CMG和TWIST现在使用相同的29 DOF配置

#### 1.1.2 运动格式转换
**当前状态**：通过 CMGMotionGenerator 直接集成，无需转换

- [x] **已完成：通过 CMGMotionGenerator 实现实时集成**
  - **实施日期**：2026年1月30日
  - 文件：`CMG_Ref/utils/cmg_motion_generator.py`
  - **解决方案**：直接在训练循环中生成参考动作，无需格式转换
  - 优势：
    - 无需预先转换和存储大量轨迹文件
    - 支持实时动态命令更新
    - 内存效率更高
  - 如需离线格式转换，可使用：
    - 函数：`cmg_npz_to_twist_format(cmg_npz, output_pkl)`
    - 必需字段：
      ```python
      {
        'dof_positions': [T, 29],  # 29 DOF
        'dof_velocities': [T, 29],  # 29 DOF
        'body_positions': [T, num_bodies, 3],
        'body_rotations': [T, num_bodies, 4],  # 四元数
        'fps': 50,
        'dof_names': List[str],
        'body_names': List[str]
      }
      ```

#### 1.1.3 前向运动学实现
**当前状态**：未实现

- [ ] **从关节角度计算身体变换**
  - 使用现有的 FK：`pose/pose/util_funcs/kinematics_model.py`
  - 输入：关节位置 [29 DOF]  # 更新为29 DOF
  - 输出：所有身体的位置和旋转
  - 集成到运动转换器中
  - 测试：比较计算的与参考身体位置

#### 1.1.4 G1 训练数据准备
**当前状态**：✅ 配置已对齐，CMG的29 DOF可直接使用

- [x] **DOF配置已对齐**
  - ✅ CMG使用29 DOF（已训练）
  - ✅ TWIST使用29 DOF（已更新）
  - ✅ 无需重新训练CMG
  - 数据源：从 TWIST 现有动作库中提取
  - 处理步骤：
    - 将 TWIST PKL 转换为 CMG 训练格式
    - 从根部运动计算速度命令
    - 应用数据过滤（仅限运动）
    - 计算统计信息（均值、标准差、最小值、最大值）
  - 文件：`CMG_Ref/dataloader/prepare_g1_data.py`
  - 输出：`cmg_g1_training_data.pt`
  - 重新训练：
    - 用 `motion_dim = 46`（23 pos + 23 vel）更新 `train.py`
    - 训练 400 个 epochs
    - 验证生成的动作

---

## 第 2 阶段：集成与实时管道

### 2.1 集成与实时管道
**优先级**：HIGH  
**工作量**：Medium

#### 2.1.1 CMG-TWIST 桥接类 ✅ **已完成**
**当前状态**：✅ 高效双模式实现完成

- [x] **已完成：CMGMotionGenerator 类**
  - **实施日期**：2026年1月30日
  - 文件：`CMG_Ref/utils/cmg_motion_generator.py`
  - 类名：`CMGMotionGenerator`
  - **双模式支持**：
    - **预生成模式 (Pregenerated)**：批量生成完整轨迹，用于训练冷启动
    - **实时推理模式 (Realtime)**：自回归生成+缓冲区，用于动态命令跟踪
  - 主要方法：
    - `__init__(model_path, num_envs, mode, ...)`：初始化生成器
    - `reset(env_ids, init_motion, commands)`：重置环境状态
    - `get_motion(env_ids)`：获取参考动作 (dof_pos, dof_vel)
    - `update_commands(commands, env_ids)`：更新速度命令
    - `switch_mode(new_mode)`：动态切换工作模式
    - `get_performance_stats()`：性能统计
  - **性能优化**：
    - 支持4096并行环境
    - 批量自回归生成
    - 预计算归一化统计
    - 智能缓冲区管理
  - **附加工具**：
    - `CommandSmoother`: 命令平滑器
    - `CommandSampler`: 多样化命令采样
  - 测试脚本：`CMG_Ref/test_motion_generator.py`
  - 集成文档：`CMG_Ref/utils/README_INTEGRATION.md`

#### 2.1.2 高层运动服务器集成
**当前状态**：固定速度命令，无 CMG 模式

- [ ] **在 server_high_level_motion_lib.py 中集成 CMG 生成器**
  - 当前：速度命令固定（例如 [1.5, 0, 0]）
  - **建议**：添加 CMG 生成模式并支持命令
  - 新参数：
    - `--use_cmg`：启用 CMG 动作生成
    - `--cmg_model_path`：训练好的 CMG 模型路径
    - `--use_cmg_command_input`：启用命令输入（键盘/手柄/语音）
  - 功能：
    - 从速度命令生成动作
    - 发送到 Redis 缓冲区供低层控制器使用
    - 支持执行期间的命令切换
  - 实现：
    - 在服务器启动时初始化 CMGMotionGenerator
    - 从输入接口接收命令
    - 以 50 Hz 生成动作帧
    - 写入共享缓冲区

#### 2.1.3 命令输入与插值
**当前状态**：仅固定速度命令，无用户输入

- [ ] **实现平滑命令输入和插值**
  - 当前：速度固定为 [1.5, 0, 0]，无用户输入
  - **方案 A - 键盘控制**：
    - W/S：前进/后退（vx）
    - A/D：左/右平移（vy）
    - Q/E：旋转（yaw）
    - +/-：速度调整
  - **方案 B - 游戏手柄/摇杆**：
    - 左摇杆：(vx, vy) 模拟控制
    - 右摇杆：yaw 旋转
    - 触发按钮：速度调整
  - **方案 C - 语音命令**：
    - "向前走"、"左转"、"停止"
    - 转换为速度命令
  - 平滑插值：
    - 避免速度突变
    - 在 0.2-0.5 秒内逐渐调整速度
    - 平滑的命令过渡

#### 2.1.4 实时生成优化
**当前状态**：episode 重置时批量生成，无实时自适应

- [ ] **优化推理速度并处理命令变更**
  - 当前：在 episode 开始时生成 2 秒轨迹，之后静态
  - 问题：
    - 不支持动作中期的命令变更
    - 可能存在性能峰值
    - 无实时响应性
  - **优化目标**：
    - 推理时间：< 20ms/帧（50 Hz 要求）
    - 启用每 0.1-0.5 秒的命令更新
    - 预生成动作缓冲区（提前 1-2 秒）
  - 实现：
    - 分析当前推理速度（cuda/cpu）
    - 如需优化：量化、TorchScript JIT
    - 使用动作缓冲区：维护接下来 N 帧的队列
    - 在命令变更或缓冲区耗尽时重新生成
    - 序列过渡时平滑混合
  - 代码结构：
    ```python
    class CMGMotionGenerator:
        def __init__(self, model, buffer_size=100):  # ~2s at 50Hz
            self.buffer = deque(maxlen=buffer_size)
            self.current_cmd = [0, 0, 0]
        
        def get_next_frame(self):
            if len(self.buffer) < buffer_size/2:
                self._refill_buffer()
            return self.buffer.popleft()
        
        def update_command(self, vx, vy, yaw):
            # 平滑过渡到新命令
            self._interpolate_command(vx, vy, yaw)
            # 计划缓冲区重新生成
        
        def _refill_buffer(self):
            # 用当前命令生成接下来 N 帧
            pass
    ```

---

## 第 3 阶段：坐标系与测试

### 3.1 坐标系与测试
**优先级**：MEDIUM  
**工作量**：Low-Medium

#### 3.1.1 坐标系对齐与转换
**当前状态**：未讨论，部署时关键

- [ ] **文档并对齐坐标系**
  - CMG 框架：机器人中心（前=+X，左=+Y，上=+Z）
  - TWIST 框架：机器人跟踪的世界框架
  - **必需的转换**：
    - 速度命令框架（输入）→ 机器人框架（CMG 输入）
    - CMG 输出（机器人框架）→ 世界框架（TWIST 输入）
  - 实现：
    - 文件：`CMG_Ref/utils/frame_transforms.py`
    - 函数：
      - `cmd_to_robot_frame(v_world)`：将命令转换到机器人框架
      - `motion_to_world_frame(motion_robot)`：转换动作输出
    - 验证：
      - 验证前进命令使机器人沿正确方向移动
      - 测试原地旋转
      - 验证横向运动
  - 测试：
    - 在 MuJoCo 中进行视觉检查
    - 真实机器人部署（有绳）

#### 3.1.2 系统测试与验证
**当前状态**：仅记录了训练过程，无验证计划

- [ ] **制定综合测试计划**
  - **仿真测试**：
    - 各种速度命令（前进、后退、横移、转向）
    - 命令响应时间和平滑度
    - 压力测试：突然变更、最大速度、长时间运行
    - 误差跟踪：与预期轨迹的偏差
    - 对比 CMG 生成与动捕参考动作
  
  - **物理机器人测试**（仿真通过后）：
    - 平地上的有绳行走
    - 基本运动稳定性和安全性
    - 命令响应性
    - 对干扰的鲁棒性
    - 不平地行走（如适用）
  
  - **安全验证**：
    - 关节角度限制执行
    - 速度/扭矩限制
    - 跌倒检测
    - 紧急停止功能

#### 3.1.3 安全与优化措施
**当前状态**：仅基本关节跟踪，无安全/能量优化

- [ ] **实现安全特性和运动优化**
  - **安全措施**：
    - 紧急停止（kill switch）
    - 关节角度硬限制和软边界
    - 速度饱和（防止超速）
    - 扭矩/功率限制
    - 跌倒检测和恢复
  
  - **运动质量优化**：
    - 调整 CMG 生成参数
    - 调整 TWIST 跟踪权重（参考 [508]）
    - 改进平滑度和自然性
    - 能量效率分析
  
  - **性能优化**：
    - 降低延迟（目标：< 50ms 总延迟）
    - 优化推理速度（目标：< 20ms）
    - 最小化抖动和不连续性
    - 分析关键路径

---

## 第 4 阶段：观察和奖励改进

### 4.1 观察和奖励改进
**优先级**：MEDIUM  
**工作量**：Low-Medium

#### 4.1.1 足接触与关节扭矩观察
**当前状态**：仅限于位置/速度，无力反馈

- [ ] **将足接触感应添加为本体感知反馈**
  - 当前：仅关节 pos/vel + 有限的特权信息
  - 添加二值足接触传感器：`[batch, 2]`（左、右脚）
  - 优势：
    - 更好的地面接触感知
    - 改进的步态相位检测
    - 更鲁棒的地形自适应
  - 实现：
    - 使用 MuJoCo 接触传感器或从接触力计算
    - 包含在教师和学生观察中
    - 归一化到 [0, 1] 范围

- [ ] **在观察中包含关节扭矩反馈**
  - 当前：缺少实际扭矩信息
  - 添加关节扭矩：`[batch, 23]`（所有 23 DOF）
  - 优势：
    - 力感知以供控制
    - 更好的阻抗调节
    - 通过策略改进力感知
  - 实现：
    - 从模拟器提取：`data.qfrc_applied` 或 `data.qfrc_constraint`
    - 按最大扭矩限制归一化
    - 包含在本体感知观察中
    - 更新观察维度：`n_proprio += 23 + 2 = +25 dims`

#### 4.1.2 丰富奖励函数
**当前状态**：仅关节跟踪，无显式速度/姿态惩罚

- [ ] **添加综合运动奖励组件**
  - 当前奖励重点关注跟踪（参考 [508]）
  - **建议添加的项**：
  
    a. **线速度跟踪**：
    ```python
    r_lin_vel = -w_lin * ||v_base - v_cmd||²  # w_lin = 1.0
    ```
  
    b. **角速度跟踪**：
    ```python
    r_ang_vel = -w_ang * ||ω_base - ω_cmd||²  # w_ang = 0.5
    ```
  
    c. **基座方向（保持直立）**：
    ```python
    r_orient = -w_orient * ||proj_gravity - [0,0,-1]||²  # w_orient = 1.0
    ```
  
    d. **足滑惩罚**：
    ```python
    r_slip = -w_slip * Σ(||v_foot_xy|| * contact)  # w_slip = 0.1
    ```
  
    e. **动作率惩罚**：
    ```python
    r_action_rate = -w_rate * ||action_t - action_{t-1}||²  # w_rate = 0.01
    ```
  
  - 实现：
    - 更新 `g1_mimic_distill_config.py` 奖励权重
    - 将这些项添加到环境中的 compute_reward()
    - 记录各个组件以便调试
    - 通过训练迭代调整权重

#### 4.1.3 步态相位指导
**当前状态**：无显式相位信号，通过未来帧隐式推断

- [ ] **添加步态相位输入来指导策略**
  - 当前：TWIST 从参考动作的未来帧隐式推断步态
  - **显式信号的优势**：
    - 更好的摆动/支撑同步
    - 改进的足部放置时序
    - 更自然的步态过渡
  - **实现选项**：
    - **选项 A - 正弦相位**（每条腿）：
      ```python
      phase_left = sin(2π * t * freq)   # 左腿相位
      phase_right = sin(2π * t * freq + π)  # 右腿相位（偏移）
      # 添加到观察：[batch, 4]（每条腿的 sin/cos）
      ```
    - **选项 B - 离散步态状态**：
      ```python
      gait_state = [L_stance, L_swing, R_stance, R_swing]  # 类似 one-hot
      # 形状：[batch, 4]
      ```
    - **选项 C - 未来接触计划**：
      ```python
      contact_schedule = future_ref_contacts[t:t+horizon]  # [batch, horizon, 2]
      ```
  - 添加到观察空间（教师和学生）
  - 更新 `n_proprio` 或创建单独的步态观察组

---

## 第 5 阶段：地形适应与环境生成

### 5.1 地形适应与环境生成
**优先级**：HIGH  
**工作量**：High

#### 5.1.1 增强特权地形信息
**当前状态**：仅平地，无地形感知训练

- [ ] **向教师观察添加地形高度图**
  - 当前：特权观察中无地形信息
  - 优势：
    - 训练期间更好的地形自适应
    - 通过知识蒸馏获得更鲁棒的学生策略
    - 支持复杂地形行走
  - **选项 A - 高度图方法**：
    ```python
    # 基于栅格的地形采样
    terrain_height_map: [batch, grid_size, grid_size]  # 例如 20×20
    # 采样机器人下方/前方区域（1m × 1m，分辨率 0.05m）
    ```
  - **选项 B - 射线投射方法**：
    ```python
    # 定向地形感知
    terrain_rays: [batch, num_rays, 2]  # 每条射线的距离 + 高度
    # 16 条射线 × 2 = 32 dims（更高效）
    ```
  - 实现：
    - 向特权观察添加高度图传感器
    - 更新训练配置中的观察空间
    - 在教师策略输入中包含地形特征
    - 确保学生最终可以访问类似信息

#### 5.1.2 可配置地形生成器
**当前状态**：仅平地，无程序生成

- [ ] **实现程序化地形和难度课程**
  - 当前：所有训练都在平地上，无复杂性变化
  - **支持的地形类型**：
    - 平地（基线）
    - 斜坡（0-15° 可调）
    - 楼梯（5-15cm 高度、20-40cm 深度）
    - 随机粗糙地形（Perlin 噪声）
    - 踏脚石
    - 混合地形组合
  
  - **摩擦力变化**：
    ```python
    friction_range = [0.4, 1.2]  # 低（冰~0.1）到高（橡胶~1.0）
    # 为域随机化在每个地形补丁中随机化
    ```
  
  - **难度课程**：
    ```python
    difficulty_schedule = {
        0: "flat",           # 迭代 0-2k
        2000: "low_slopes",  # 迭代 2k-5k
        5000: "stairs",      # 迭代 5k-10k
        10000: "rough",      # 迭代 10k-15k
        15000: "mixed"       # 迭代 15k+
    }
    ```
  
  - 实现：
    - 文件：`legged_gym/legged_gym/envs/terrain_generator.py`
    - 类：`ProceduralTerrainGenerator`
    - 方法：
      - `generate_flat_terrain()`
      - `generate_slope_terrain(angle_range, num_slopes)`
      - `generate_stairs_terrain(step_height, step_depth)`
      - `generate_rough_terrain(roughness, frequency)`
      - `generate_mixed_terrain(difficulty_level)`
    - 配置结构：
      ```python
      terrain_config = {
          "terrain_type": "mixed",
          "terrain_size": [10.0, 10.0],  # 米
          "horizontal_scale": 0.05,      # 分辨率
          "vertical_scale": 0.005,       # 高度精度
          "slope_threshold": 0.75,       # 最大斜坡角度
          "friction_range": [0.5, 1.0],
          "restitution_range": [0.0, 0.3],
          "curriculum_enabled": True,
          "difficulty_level": 0.5  # 0.0=简单，1.0=困难
      }
      ```
  
  - 与训练集成：
    - 添加地形配置到 `g1_mimic_distill_config.py`
    - 每个 episode 或定期生成新地形
    - 在特权信息中包含地形参数
    - 应用域随机化（摩擦力、反弹系数）

#### 5.1.3 训练数据对齐与 DOF 一致性
**当前状态**：CMG 使用 29 DOF，建议在 G1 的 23 DOF 上重新训练

- [ ] **在映射和重新训练之间做出决定**
  - **选项 A - 映射方法**（更快，短期）：
    - 实现 29→23 DOF 转换函数
    - 处理未使用的关节（手指、额外的臂部 DOF）
    - 优点：重用现有 CMG 模型
    - 缺点：转换错误可能累积
  
  - **选项 B - 重新训练**（推荐，长期）：
    - 从 TWIST 动作库准备 G1 特定数据集
    - 用本地 23 DOF 支持重新训练 CMG
    - 优点：更好的动作质量，无转换开销
    - 缺点：需要训练时间（~1-2 周）
    - **强烈推荐**用于生产部署
  
  - **建议**：从选项 A 开始进行快速测试，初始验证后再做选项 B

- [ ] **DOF 统一前不添加地形复杂性**
  - 原因：映射错误可能与地形难度复合
  - 在选项 B（重新训练）完成前等待
  - 测试顺序：
    1. DOF 映射/重新训练 + 平地验证
    2. 然后引入斜坡/楼梯/粗糙地形
    3. 最后用混合地形课程训练

---

## 第 6 阶段：文档与部署

### 6.1 集成文档与部署
**优先级**：MEDIUM  
**工作量**：Medium

#### 6.1.1 集成文档完善
**当前状态**：部分文档，缺少完整集成指南

- [ ] **编写综合集成和设置指南**
  - 完整安装说明（依赖、版本）
  - 分步集成教程
  - 配置参数文档
  - 常见问题故障排除指南
  - 调试技术和性能分析

- [ ] **创建 API 文档**
  - 文档化 CMGMotionGenerator 类
  - 文档化运动转换函数
  - 文档化坐标变换函数
  - 添加类型提示和文档字符串
  - 生成参考文档

- [ ] **开发使用示例**
  - 示例：动作生成的键盘控制
  - 示例：基于摇杆的命令输入
  - 示例：批量运动转换
  - 示例：实时命令更新
  - 示例：性能监控

#### 6.1.2 部署脚本和依赖打包
**当前状态**：部署部分未讨论

- [ ] **创建部署脚本**
  - 开发的一键设置脚本
  - 生产安装脚本
  - 配置文件模板
  - 启动脚本（服务器、客户端等）
  - 环境变量设置

- [ ] **打包和组织依赖**
  - 用所有依赖更新主 requirements.txt
  - 按组件创建 requirements 文件：
    - `requirements_cmg.txt`（CMG 和转换）
    - `requirements_twist.txt`（TWIST 训练）
    - `requirements_deploy.txt`（仅部署）
  - 在干净系统上测试安装
  - 记录 Python 版本兼容性（3.8+）

- [ ] **创建 Docker 容器**（可选但推荐）
  - 带所有依赖的 Dockerfile
  - 多容器设置的 docker-compose.yml
  - 模型和数据的卷挂载
  - 环境变量配置
  - 测试镜像构建和运行时

#### 6.1.3 坐标与频率对齐
**当前状态**：频率已对齐（50 Hz），坐标尚未处理

- [ ] **文档化坐标框架对齐**
  - 参考：ProjectDocumentation.zh.md 提到 50 Hz 频率
  - 文档化 CMG 的机器人中心框架
  - 文档化 TWIST 的世界框架
  - 解释任何所需的框架转换
  - 如可能创建可视化图表

- [ ] **确保运动格式兼容性**
  - 确认 CMG 和 TWIST 之间的 50 Hz 同步
  - 文档化 PKL 格式字段和要求
  - 验证 NPZ 到 PKL 的转换
  - 测试往返转换质量

---

## 快速参考检查表

### 优先级排序的任务执行顺序

**第一周（关键路径）**：
1. 任务 1.1.1-1.1.4：DOF 映射或重新训练准备
2. 任务 1.2.1-1.2.3：运动格式转换
3. 任务 3.1.1-3.1.2：坐标系对齐

**第二周（集成）**：
4. 任务 2.1.1：CMG 模型评估与数据集准备
5. 任务 3.2.1-3.2.3：高层服务器集成
6. 任务 3.3.1-3.3.2：命令输入接口

**第三周（测试）**：
7. 任务 4.1.1-4.1.3：仿真测试
8. 任务 4.2.1-4.2.3：物理机器人测试（有绳）

**后续迭代**：
9. 任务 5.1.1-5.1.3：优化和精炼
10. 任务 6.1.1-6.1.3：文档和部署

---

## 关键依赖关系和风险

### 依赖关系
1. **CMG → TWIST**：运动格式必须兼容
2. **关节映射**：对正确的运动转移至关重要
3. **坐标框架**：必须对齐以正确方向控制
4. **定时**：两个系统必须以 50 Hz 运行

### 风险和缓解措施
1. **风险**：CMG 运动可能无法被 TWIST 跟踪
   - **缓解**：用 G1 的实际 DOF 和运动范围重新训练 CMG
   - **缓解**：在 CMG 生成数据上微调 TWIST

2. **风险**：实时性能问题
   - **缓解**：优化推理（TorchScript、量化）
   - **缓解**：预生成运动缓冲区

3. **风险**：物理机器人上的安全隐患
   - **缓解**：首先进行广泛的仿真测试
   - **缓解**：从有绳/悬挂机器人开始
   - **缓解**：实现紧急停止

4. **风险**：运动质量不佳
   - **缓解**：迭代改进 CMG 训练数据质量
   - **缓解**：在 TWIST 中调整奖励权重

---

## 成功指标

### 最小可行产品（MVP）
- [ ] 机器人可使用 CMG 命令以 0.5 m/s 向前行走
- [ ] 机器人可在命令时停止
- [ ] 系统运行 30 秒无崩溃

### 目标性能
- [ ] 以 1.0+ m/s 向前行走
- [ ] 原地转向 0.3 rad/s
- [ ] 命令间平滑过渡
- [ ] 连续运行 5+ 分钟
- [ ] 跟踪误差 < 10cm/10m

### 拓展目标
- [ ] 动态奔跑（> 1.5 m/s）
- [ ] 复杂命令（圆形、8 字形）
- [ ] 地形自适应
- [ ] 推动恢复

---

## 时间估算

**快速路径**（假设现有 CMG 模型工作）：
- 第 1 阶段：1 周（数据对齐）
- 第 2 阶段：1 周（集成）
- 第 3 阶段：3 天（仿真测试）
- 第 4 阶段：1 周（机器人测试）
- **总计**：~3-4 周

**完整路径**（包括 CMG 重新训练）：
- 第 1 阶段：1 周
- 第 2 阶段：2 周（数据准备 + 训练）
- 第 3 阶段：1 周
- 第 4 阶段：2 天
- 第 5 阶段：2 周（测试 + 迭代）
- 第 6 阶段：1 周（优化）
- **总计**：~7-8 周

---

## 后续步骤

1. **立即**：从任务 1.1.1-1.1.4 开始（DOF 映射）
2. **第 1-2 天**：任务 1.2.1-1.2.3（运动转换）
3. **第 3-4 天**：任务 2.1.1（CMG 数据准备）
4. **第 5 天**：任务 3.1.1-3.2.3（集成类）
5. **第 6 天**：任务 4.1.1（仿真测试）
6. **第 2 周+**：根据结果迭代

---

**文档版本**：2.0  
**最后更新**：2026-01-30  
**状态**：定义了所有阶段的综合集成计划

