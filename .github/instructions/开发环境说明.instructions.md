---
applyTo: '**'
---
Provide project context and coding guidelines that AI should follow when generating code, answering questions, or reviewing changes.
首先不要随便创建一堆md，除非我明确说明需要创建md文件
其次这个项目是在linux下编写，但是训练发生在服务器，因此任何尝试用本机python环境来验证的操作都是不合理的
如果需要查看可能有用的文档，请访问根目录下的documents文件夹
默认情况下请使用中文回答
项目背景为这是基于TWIST（一套TELEOP框架）+CMG作为动作参考输入而不是动捕输入，实现机器人长距离行走
参考：
# **TWIST**

简单来说这个架构分为两部分：

自回归模型+残差网络

# 自回归模型

这个模型用到了现成的人体动作数据集，然后把这个数据集重定向到目标机器人的结构上

为什么要重定向：

因为人体结构和机器人结构不一样，需要把人体动作重新映射到机器人关节角度，这样才能保证模型学到的东西差不多

这东西有什么用：

简单来说通过重定向之后的数据，就可以训练一个当前输入下输出t+1时刻的动作的模型，这个模型未必需要让输出的结果（即关节的角度）直接输入到机器人就能让他按照这个模型应该有的动作去运动，而是提供一个大差不差的参考，把这个作为引导（即通过某种手段让最终负责控制的模型的输出范围（即关节角度）限制自回归模型输出的附近，这样就可以大幅度减少RL训练过程中需要探索的状态空间，同时还能更方便的对策略的动作模式进行控制（因为可以通过修改这个参考模型的输出来影响最终的结果）

# 残差网络

正如上面提到的，自回归模型输出结果在真实世界的物理上并不可行，然而也已经大差不差，所以很自然的就能想到如果在自回归模型的输出结果后面接一个比较传统的RL模型在一定范围内修正参考量，通过奖励真正可行的动作来让正模型真正的学会怎么动作

在训练上这玩意的思路其实和上学期的Parkour很相似，也是教师+学生，教师拥有一些只能在模拟环境当中获取的先验数据，先通过这些数据让教师能多快好省的学习到正确的运动方式，然后再让学生策略使用真实能拿到的数据来训练，通过教师模型的约束可以让他也比较快的学习到正确的运动方式

在训练上有一个需要注意的技巧，是teacher的先验包括了未来2s的参考动作，非常的有MPC风味

这样就可以让模型有一定的时域稳定性，能够有效避免上学期炼狗的时候出现的抽搐问题，而采用这种风味MPC有个好处是没必要折腾MPC自己了，这样就少了很多超参数要设计

***这种教师学生的范式其实就是通过未来 reference 将原本的 POMDP(部分可观测马尔科夫决策过程) 提升为近似 MDP 进行训练，***

***再将这一前瞻性策略蒸馏回只观测当前 reference 的反应式 policy***